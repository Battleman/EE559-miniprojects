
@misc{noauthor_deep_2020,
	title = {Deep learning},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Deep_learning&oldid=954954275},
	abstract = {Deep learning  (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.Deep learning architectures such as deep neural networks, deep belief networks, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains.  Specifically, neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.},
	language = {en},
	urldate = {2020-05-06},
	journal = {Wikipedia},
	month = may,
	year = {2020},
	note = {Page Version ID: 954954275},
	file = {Snapshot:/home/battleman/Documents/Zotero/storage/GZJBWGGN/index.html:text/html}
}

@misc{noauthor_siamese_2020,
	title = {Siamese neural network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Siamese_neural_network&oldid=953925157},
	abstract = {A Siamese neural network (sometimes called a twin neural network) is an artificial neural network that uses the same weights while working in tandem on two different input vectors to compute comparable output vectors. Often one of the output vectors is precomputed, thus forming a baseline against which the other output vector is compared. This is similar to comparing fingerprints but can be described more technically as a distance function for locality-sensitive hashing.It is possible to make a kind of structure that is functional similar to a siamese network, but implements a slightly different function. This is typically used for comparing similar instances in different type sets.Uses of similarity measures where a twin network might be used are such things as recognizing handwritten checks, automatic detection of faces in camera images, and matching queries with indexed documents. The perhaps most well-known application of twin networks are face recognition, where known images of people are precomputed and compared to an image from a turnstile or similar. It is not obvious at first, but there are two slightly different problems. One is recognizing a person among a large number of other persons, that is the facial recognition problem. DeepFace is an example of such a system. In its most extreme form this is recognizing a single person at a train station or airport. The other is face verification, that is to verify whether the photo in a pass is the same as the person claiming he or she is the same person. The twin network might be the same, but the implementation can be quite different.},
	language = {en},
	urldate = {2020-05-06},
	journal = {Wikipedia},
	month = apr,
	year = {2020},
	note = {Page Version ID: 953925157},
	file = {Snapshot:/home/battleman/Documents/Zotero/storage/3W6TSH9N/index.html:text/html}
}

@misc{noauthor_convolutional_2020,
	title = {Convolutional neural network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Convolutional_neural_network&oldid=953234856},
	abstract = {In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics. They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.
CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The "fully-connectedness" of these networks makes them prone to overfitting data. Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function. CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.
Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.
CNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns the filters that in traditional algorithms were hand-engineered. This independence from prior knowledge and human effort in feature design is a major advantage.},
	language = {en},
	urldate = {2020-05-06},
	journal = {Wikipedia},
	month = apr,
	year = {2020},
	note = {Page Version ID: 953234856},
	file = {Snapshot:/home/battleman/Documents/Zotero/storage/FLIY5YMQ/index.html:text/html}
}

@misc{noauthor_search_nodate,
	title = {Search {Publications}},
	url = {https://www.researchgate.net/search?q=parameters%20sharing},
	abstract = {Discover the world's scientific knowledge {\textbar} With 15+ million researchers, 1+ million questions and 118+ million publications, this is where everyone can access science},
	language = {en},
	urldate = {2020-05-06},
	journal = {ResearchGate},
	note = {Library Catalog: www.researchgate.net},
	file = {Snapshot:/home/battleman/Documents/Zotero/storage/UZXGQ74C/search.html:text/html}
}

@book{du_adapting_2018,
	title = {Adapting {Auxiliary} {Losses} {Using} {Gradient} {Similarity}},
	abstract = {One approach to deal with the statistical inefficiency of neural networks is to rely on auxiliary losses that help to build useful representations. However, it is not always trivial to know if an auxiliary task will be helpful for the main task and when it could start hurting. We propose to use the cosine similarity between gradients of tasks as an adaptive weight to detect when an auxiliary loss is helpful to the main loss. We show that our approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains: multi-task supervised learning on subsets of ImageNet, reinforcement learning on gridworld, and reinforcement learning on Atari games.},
	author = {Du, Yunshu and Czarnecki, Wojciech and Jayakumar, Siddhant and Pascanu, Razvan and Lakshminarayanan, Balaji},
	month = dec,
	year = {2018},
	file = {Full Text PDF:/home/battleman/Documents/Zotero/storage/6QVQUNL8/Du et al. - 2018 - Adapting Auxiliary Losses Using Gradient Similarit.pdf:application/pdf}
}

@article{trinh_learning_2018,
	title = {Learning {Longer}-term {Dependencies} in {RNNs} with {Auxiliary} {Losses}},
	abstract = {Despite recent advances in training recurrent neural networks (RNNs), capturing long-term dependencies in sequences remains a fundamental challenge. Most approaches use backpropagation through time (BPTT), which is difficult to scale to very long sequences. This paper proposes a simple method that improves the ability to capture long term dependencies in RNNs by adding an unsupervised auxiliary loss to the original objective. This auxiliary loss forces RNNs to either reconstruct previous events or predict next events in a sequence, making truncated backpropagation feasible for long sequences and also improving full BPTT. We evaluate our method on a variety of settings, including pixel-by-pixel image classification with sequence lengths up to 16{\textbackslash},000, and a real document classification benchmark. Our results highlight good performance and resource efficiency of this approach over competitive baselines, including other recurrent models and a comparable sized Transformer. Further analyses reveal beneficial effects of the auxiliary loss on optimization and regularization, as well as extreme cases where there is little to no backpropagation.},
	author = {Trinh, Trieu and Dai, Andrew and Thắng, Lương and Le, Quoc},
	month = feb,
	year = {2018}
}

@inproceedings{varga_using_2018,
	title = {Using {Auxiliary} {Loss} to {Improve} {Sleep} {Arousal} {Detection} {With} {Neural} {Network}},
	doi = {10.22489/CinC.2018.247},
	author = {Varga, Bálint and Görög, Márton and Hajas, Peter},
	month = dec,
	year = {2018}
}

@article{hu_anytime_2017,
	title = {Anytime {Neural} {Networks} via {Joint} {Optimization} of {Auxiliary} {Losses}},
	abstract = {We address the problem of anytime prediction in neural networks. An anytime predictor automatically adjusts to and utilizes available test-time budget: it produces a crude initial result quickly and continuously refines the result afterwards. Traditional feed-forward networks achieve state-of-the-art performance on many machine learning tasks, but cannot produce anytime predictions during their typically expensive computation. In this work, we propose to add auxiliary predictions in a residual network to generate anytime predictions, and optimize these predictions simultaneously. We solve this multi-objective optimization by minimizing a carefully constructed weighted sum of losses. We also oscillate weightings of the losses in each iteration to avoid spurious solutions that are optimal for the sum but not for each individual loss. The proposed approach produces competitive results if computation is interrupted early, and the same level of performance as the original network once computation is finished. Observing that the relative performance gap between the optimal and our proposed anytime network shrinks as the network is near completion, we propose a method to combine anytime networks to achieve more accurate anytime predictions with a constant fraction of additional cost. We evaluate the proposed methods on real-world visual recognition data-sets to demonstrate their anytime performance.},
	author = {Hu, Hanzhang and Dey, Debadeepta and Bagnell, J. and Hebert, Martial},
	month = aug,
	year = {2017}
}

@article{szegedy_going_2014,
	title = {Going {Deeper} with {Convolutions}},
	url = {http://arxiv.org/abs/1409.4842},
	abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	urldate = {2020-05-06},
	journal = {arXiv:1409.4842 [cs]},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.4842},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/battleman/Documents/Zotero/storage/W75RUECL/Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:application/pdf;arXiv.org Snapshot:/home/battleman/Documents/Zotero/storage/QR4L4LT6/1409.html:text/html}
}

@misc{lecun_mnist_1998,
	title = {{MNIST} handwritten digit database},
	url = {http://yann.lecun.com/exdb/mnist/},
	urldate = {2020-05-17},
	author = {LeCun, Yann and Cortes, Corinna and Burges, Chris},
	year = {1998},
	file = {MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges:/home/battleman/Documents/Zotero/storage/EZ47SC3I/mnist.html:text/html}
}
